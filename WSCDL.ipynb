{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WSCDL.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenhao1umbc/WSCDL/blob/master/WSCDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0g6kDLSFejm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zntwRHSyroC",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My\\ Drive/Streaming_AE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_WB52Hl_q6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "from utils.training_tools import *\n",
        "from utils.custom_layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yI8lU2UK84YM",
        "colab": {}
      },
      "source": [
        "\"This is a pytorch version of Ensemble Auto-encoder \"\n",
        "##\n",
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from utils.data_loader import *\n",
        "from utils.validation_tools import *\n",
        "import os\n",
        "import pdb\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "##\n",
        "class Att(nn.Module):\n",
        "    def __init__(self, attention_size):\n",
        "        super(Att, self).__init__()\n",
        "        self.fc0 = nn.Linear(config['hidden_size'], config['attention_size'], bias=True)\n",
        "        self.fc1 = nn.Linear(config['attention_size'], 1, bias=False)\n",
        "\n",
        "    def forward(self, inputs):  # input shape is (time_size, bat_size, dim_size) = (T,B,D), D is hidden_size\n",
        "        inputs = inputs.permute(1, 0, 2)  # to (B,T,D)\n",
        "        v = torch.tanh(self.fc0(inputs))  # (B,T,D)*(D,A) = (B,T,A)\n",
        "        vu = self.fc1(v)  # to (B,T)\n",
        "        alphas = torch.nn.functional.softmax(vu)  # (B,T,1)\n",
        "        output = torch.sum(inputs * alphas, dim=1)  # (B, D)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Lstm(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(Lstm, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)  # input (time_size, bat_size, dim_size)\n",
        "\n",
        "    def forward(self, inputs):  # input shape is (time_size, bat_size, dim_size)\n",
        "        output, _ = self.lstm(inputs)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # this part need some calculation based on how the CNN is defined\n",
        "        pooling_size = 1\n",
        "        cnn_out_size0 = int((config['seq_len'] - 2 * (config['CNN_kernel_size'] - 1)) / pooling_size) \\\n",
        "                        - 2 * (config['CNN_kernel_size'] - 1)\n",
        "        cnn_out_size1 = cnn_out_size0 + 4*(config['CNN_kernel_size'] - 1) # means 4 convolutions\n",
        "\n",
        "        # this part is the FC encoder\n",
        "        self.FC_encoder = nn.Sequential(\n",
        "            nn.Linear(config['seq_len'], config['feature_size']),  # (input_size, output_size)\n",
        "            nn.Dropout(config['drop_rate'])  # activate function could be changed\n",
        "        )\n",
        "\n",
        "        # this part is the FC decoder\n",
        "        self.FC_decoder = nn.Sequential(\n",
        "            nn.Linear(config['feature_size'], config['seq_len']),  # (input_size, output_size)\n",
        "            nn.Dropout(config['drop_rate'])  # activate function could be changed\n",
        "        )\n",
        "\n",
        "        # this part is the CNN encoder\n",
        "        kernel_size = config['CNN_kernel_size']\n",
        "        self.CNN_encoder = nn.Sequential(\n",
        "            nn.Conv1d(1, 128, kernel_size, stride=1, padding=0),  # Channels_in, Chnannels_out, Kernal_size\n",
        "            nn.BatchNorm1d(128, eps=0.001, momentum=0.01),  # L, input is N*C*L or N*C\n",
        "            nn.Conv1d(128, 64, kernel_size),  # default stride=1, padding=0, dilation=1\n",
        "            nn.BatchNorm1d(64, eps=0.001, momentum=0.01),\n",
        "            nn.Conv1d(64, 32, kernel_size),\n",
        "            nn.BatchNorm1d(32, eps=0.001, momentum=0.01),\n",
        "            nn.Conv1d(32, 1, kernel_size),\n",
        "            nn.Linear(cnn_out_size0, config['feature_size']),\n",
        "            nn.ReLU(True),  # inplace=True, means save GPU memory, but covering old value\n",
        "        )\n",
        "\n",
        "        # this is the CNN decoder\n",
        "        self.CNN_decoder = nn.Sequential(\n",
        "            nn.Linear(config['feature_size'], cnn_out_size0), # refer to CNN_encoder for the parameters\n",
        "            nn.ReLU(True),  # inplace=True, means save GPU memory, but covering old value\n",
        "            nn.ConvTranspose1d(1, 32, kernel_size),\n",
        "            nn.BatchNorm1d(32, eps=0.001, momentum=0.01),\n",
        "            nn.ConvTranspose1d(32, 64, kernel_size),\n",
        "            nn.BatchNorm1d(64, eps=0.001, momentum=0.01),\n",
        "            nn.ConvTranspose1d(64, 128, kernel_size),\n",
        "            nn.BatchNorm1d(128, eps=0.001, momentum=0.01),\n",
        "            nn.ConvTranspose1d(128, 1, kernel_size, stride=1, padding=0),\n",
        "            nn.Linear(cnn_out_size1, config['seq_len'])\n",
        "        )\n",
        "\n",
        "        # LSTM encoder\n",
        "        self.LSTM_encoder = nn.Sequential(\n",
        "            Lstm(1, config['hidden_size'], config['num_layers']),  # input (time_size, bat_size, dim_size)\n",
        "            nn.Dropout(config['drop_rate']),\n",
        "            Att(config['attention_size']),\n",
        "            nn.Linear(config['hidden_size'], config['feature_size'], bias=True)\n",
        "        )\n",
        "\n",
        "        # LSTM decoder\n",
        "        self.LSTM_decoder = nn.LSTM(2, config['hidden_size'], config['num_layers'])\n",
        "\n",
        "        # this is stacked features into regular feature length\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(3 * config['feature_size'], config['feature_size']),\n",
        "            nn.Dropout(config['drop_rate'])\n",
        "        )\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(config['feature_size'], config['hidden_size'])\n",
        "        self.fc2 = nn.Linear(config['hidden_size'], 1)\n",
        "\n",
        "    # this part defines the structure of the network\n",
        "    def forward(self, x):\n",
        "        # FC_encoder\n",
        "        x_part1 = self.FC_encoder(x)  # input x is (N,C,L)\n",
        "\n",
        "        # CNN_encoder\n",
        "        x_part2 = self.CNN_encoder(x)\n",
        "\n",
        "        # LSTM_encoder\n",
        "        x_part3 = self.LSTM_encoder(x.permute(2, 0, 1))  # input x is (L,N,C)\n",
        "\n",
        "        # latent features for classification\n",
        "        x_stack1 = self.dense(torch.cat((x_part1, x_part2, x_part3.unsqueeze(1)), dim=2))  # stack the encoder output\n",
        "\n",
        "        # FC_decoder\n",
        "        x_dc1 = self.FC_decoder(x_stack1)\n",
        "\n",
        "        # CNN_decoder\n",
        "        x_dc2 = self.CNN_decoder(x_stack1)\n",
        "\n",
        "        # LSTM decoder\n",
        "        x_stack2 = torch.cat((x_dc1, x_dc2), dim=1)  # statcked into 2 channels\n",
        "        x_temp = self.fc1(x_stack1)  # (N, C, L=hidden_size)\n",
        "        h_0 = x_temp.permute(1, 0, 2)  # (num_layers * num_directions, batch, hidden_size)\n",
        "        c_0 = x_temp.permute(1, 0, 2)  # (num_layers * num_directions, batch, hidden_size)\n",
        "        t_oupt, _ = self.LSTM_decoder(x_stack2.permute(2, 0, 1),\n",
        "                                      (h_0, c_0))  # (L,N,C) the stacked features as good intialization\n",
        "        output = self.fc2(t_oupt)\n",
        "\n",
        "        return output.permute(1, 2, 0), x_stack1\n",
        "\n",
        "\n",
        "##\n",
        "# config setting\n",
        "start_time =time.time()\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "config = {}\n",
        "config['attention_size'] = 64\n",
        "config['batch_size'] = 32\n",
        "config['crd'] = 1\n",
        "config['CNN_kernel_size'] = 4\n",
        "config['drop_rate'] = 0.2\n",
        "config['epochs'] = 300\n",
        "config['feature_size'] = 64  # number of units in the latent space\n",
        "config['hidden_size'] = 128\n",
        "config['learning_rate'] = 0.005\n",
        "config['log_dir'] = 'logs'\n",
        "config['max_grad_norm'] = 5  # maximum gradient  norm during training, cap for gradient norm\n",
        "config['num_layers'] = 1\n",
        "config['save_model'] = False\n",
        "config['sd'] = 1  ## input channel length, may need to coordinate with kernel specificiation\n",
        "config['warning'] = False  # False means silent warnings\n",
        "warnings.simplefilter(\"ignore\") if not config['warning'] else ''\n",
        "torch.set_default_dtype(torch.double) # this controls DNN dtype, change data dtype in load_data_stream\n",
        "\n",
        "# training stage\n",
        "dataset_list = ['50words', 'Adiac', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'Car', 'CBF',\n",
        "                'ChlorineConcentration', 'CinC_ECG_torso', 'Coffee', 'Computers', 'Cricket_X', 'Cricket_Y', 'Cricket_Z',\n",
        "                'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW',\n",
        "                'Earthquakes', 'ECG200', 'ECG5000']\n",
        "accuracies = {}\n",
        "for dataset in dataset_list[0:1]:  # for the testing just first data set\n",
        "#     X_train, X_test, y_train, y_test = load_data('Stream_data/', dataset) # shuffled\n",
        "\n",
        "    # for colab\n",
        "    X_train, y_train, X_test, y_test = load_data('Dataset/', dataset)\n",
        "    X_train, X_test = torch.from_numpy(X_train).permute(0,2,1), torch.from_numpy(X_test).permute(0,2,1)\n",
        "    \n",
        "    config['seq_len'] = X_train.shape[2]  # data shape is #(N, C, L)\n",
        "    loss_val_all = []\n",
        "    model = Net(config)\n",
        "    lossfunc = nn.MSELoss()\n",
        "    if torch.cuda.device_count() > 0:\n",
        "        model = nn.DataParallel(model.cuda())# .cuda() means GPU0 as controller\n",
        "        X_train = X_train.cuda()\n",
        "        X_test = X_test.cuda()\n",
        "        print('\\nGPU is available and training on GPU')\n",
        "        print('Good, we are now using multiple GPUs') if torch.cuda.device_count() > 1 else ''\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    ad_lr = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1) # exponetially decay, lr = lr*gamma\n",
        "    # training stage\n",
        "    for i in range(config['epochs']):\n",
        "        model.train()\n",
        "        outputs, _ = model(X_train)\n",
        "        loss = lossfunc(X_train, outputs)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ad_lr.step() # change the learning rate\n",
        "        torch.cuda.empty_cache() # save GPU memory\n",
        "\n",
        "        # check validate value to prevent overfitting\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Dropout):\n",
        "                m.eval()\n",
        "        with torch.no_grad():\n",
        "            loss_val = lossfunc(X_test, model(X_test)[0])\n",
        "            loss_val_all.append(loss_val)\n",
        "        if early_stop(loss_val_all):\n",
        "            print('Finished epochs: %6s / %6s : training loss = %5.5f, validation loss = %5.5f'\n",
        "                  % (i + 1, config['epochs'], loss.detach().cpu(), loss_val.cpu()))\n",
        "            print('early stop')\n",
        "            break\n",
        "        # if (i+1)%10 == 0:\n",
        "        print('Finished epochs: %6s / %6s : training loss = %5.5f, validation loss = %5.5f'\n",
        "              % (i + 1, config['epochs'], loss.detach().cpu(), loss_val.cpu()))\n",
        "\n",
        "    # validation stage    \n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Dropout):\n",
        "            m.eval()\n",
        "    with torch.no_grad():\n",
        "        val, features_train = model(X_train)\n",
        "        _, features_test = model(X_test)\n",
        "        f_tr = features_train.detach().to('cpu').numpy().squeeze()\n",
        "        f_te = features_test.detach().to('cpu').numpy().squeeze()\n",
        "        clf_results = classify_features(f_tr, y_train, f_te, y_test)\n",
        "        print(dataset, clf_results)\n",
        "        accuracies[dataset] = clf_results\n",
        "        torch.cuda.empty_cache()  # save GPU memory\n",
        "\n",
        "print(accuracies)\n",
        "print('complete')\n",
        "print('The overall time is : ', time.time()-start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wExXFBpM833S",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train.cpu().numpy().squeeze())\n",
        "plt.figure()\n",
        "plt.imshow(val.cpu().numpy().squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}